[config]

mode = eval
pretrained_model = meta-llama/Llama-3.2-1B
language = fra_Latn

# Model
max_tokens = 256
batch_size = 16
